{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34db9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7839b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'CRYPTOBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c86278fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = 'crypto_bitcoin'\n",
    "# crypto = 'crypto_ethereum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64cdc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subs = ['bitcoin','bitcoinbeginners','bitcoinmarkets','bitcoinmining','btc']\n",
    "# list_subs = ['ethereum','ethermining','ethfinance','eth','ethtrader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "202f9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for subreddit in list_subs:\n",
    "    dfs.append(pd.read_csv(f\"Data/Sentiment/{crypto}/{model}/{subreddit}_sentiment_submission_19_22.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ac3798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3951d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bitcoin', 'BitcoinBeginners', 'BitcoinMarkets', 'BitcoinMining',\n",
       "       'btc'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['subreddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a421d0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['submission', 'post_text', 'subreddit', 'score', 'num_comments',\n",
       "       'posted_on', '# Of Words', 'label', 'score.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c18b74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['posted_on'] = pd.to_datetime(final_df['posted_on'])\n",
    "\n",
    "# Set the 'posted_on' as the index\n",
    "final_df.set_index('posted_on', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d86173",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'VADER':\n",
    "    final_df['VADER_Post_Sentiment'] = pd.Categorical(final_df['VADER_Post_Sentiment'], categories=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    # Create a DataFrame to store the aggregated statistics\n",
    "    aggregated_df = pd.DataFrame()\n",
    "\n",
    "    # Count the occurrences of each sentiment category per day\n",
    "    aggregated_df['positive_count'] = final_df['VADER_Post_Sentiment'].eq('Positive').groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['negative_count'] = final_df['VADER_Post_Sentiment'].eq('Negative').groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['neutral_count'] = final_df['VADER_Post_Sentiment'].eq('Neutral').groupby(pd.Grouper(freq='D')).sum()\n",
    "    \n",
    "    # Aggregating other features\n",
    "    aggregated_df['total_posts'] = final_df['submission'].groupby(pd.Grouper(freq='D')).size()\n",
    "    aggregated_df['total_words'] = final_df['# Of Words'].groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['total_stopwords'] = final_df['# Of StopWords'].groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['total_comments'] = final_df['num_comments'].groupby(pd.Grouper(freq='D')).sum()\n",
    "\n",
    "    # Mean of 'Average Word Length' per day\n",
    "    aggregated_df['average_word_length'] = final_df['Average Word Length'].groupby(pd.Grouper(freq='D')).mean()\n",
    "\n",
    "    # Mean of 'VADER_Score' per day\n",
    "    aggregated_df['mean_vader_score'] = final_df['VADER_Score'].groupby(pd.Grouper(freq='D')).mean()\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    aggregated_df.fillna(0, inplace=True)\n",
    "\n",
    "    # # Print the aggregated DataFrame\n",
    "    display(aggregated_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4fb4655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>neutral_count</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_on</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "      <td>8369</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>90</td>\n",
       "      <td>12730</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>113</td>\n",
       "      <td>15544</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>95</td>\n",
       "      <td>9832</td>\n",
       "      <td>1388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive_count  negative_count  neutral_count  total_posts  \\\n",
       "posted_on                                                                \n",
       "2019-01-01              23               3             37           63   \n",
       "2019-01-02              35               7             48           90   \n",
       "2019-01-03              44              11             58          113   \n",
       "2019-01-04              31               3             61           95   \n",
       "\n",
       "            total_words  total_comments  \n",
       "posted_on                                \n",
       "2019-01-01         8369             989  \n",
       "2019-01-02        12730            1150  \n",
       "2019-01-03        15544            1784  \n",
       "2019-01-04         9832            1388  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model == 'CRYPTOBERT':\n",
    "    final_df['label'] = pd.Categorical(final_df['label'], categories=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    # Create a DataFrame to store the aggregated statistics\n",
    "    aggregated_df = pd.DataFrame()\n",
    "\n",
    "    # Count the occurrences of each sentiment category per day\n",
    "    aggregated_df['positive_count'] = final_df['label'].eq('Positive').groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['negative_count'] = final_df['label'].eq('Negative').groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['neutral_count'] = final_df['label'].eq('Neutral').groupby(pd.Grouper(freq='D')).sum()\n",
    "\n",
    "    # Aggregating other features\n",
    "    aggregated_df['total_posts'] = final_df['submission'].groupby(pd.Grouper(freq='D')).size()\n",
    "    aggregated_df['total_words'] = final_df['# Of Words'].groupby(pd.Grouper(freq='D')).sum()\n",
    "    aggregated_df['total_comments'] = final_df['num_comments'].groupby(pd.Grouper(freq='D')).sum()\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    aggregated_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Print the aggregated DataFrame\n",
    "    display(aggregated_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fa8ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index to make 'posted_on' a column\n",
    "aggregated_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dee317c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posted_on         0\n",
       "positive_count    0\n",
       "negative_count    0\n",
       "neutral_count     0\n",
       "total_posts       0\n",
       "total_words       0\n",
       "total_comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ea197",
   "metadata": {},
   "source": [
    "### Saving the Count Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217098f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df.to_csv(f\"Data/Time_Series/{crypto}/{model}_sts_19_22.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
